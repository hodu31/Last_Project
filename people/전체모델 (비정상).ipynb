{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_1 = \"./data/이상(방화)\"\n",
    "folder_path_2 = \"./data/이상(유기)\"\n",
    "folder_path_3 = \"./data/이상(전도)\"\n",
    "folder_path_4 = \"./data/이상(절도)\"\n",
    "folder_path_5 = \"./data/이상(파손)\"\n",
    "folder_path_6 = \"./data/이상(폭행)\"\n",
    "folder_path_7 = \"./data/이상(흡연)\"\n",
    "#folder_path_7 = \"./data/이상(교통약자)\"\n",
    "folder_path_8 = \"./data/구매(구매)\"\n",
    "folder_path_9 = \"./data/구매(반품)\"\n",
    "folder_path_10 = \"./data/구매(비교)\"\n",
    "folder_path_11 = \"./data/구매(선택)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(path):\n",
    "    file_lst = os.listdir(path)\n",
    "    df_list = []\n",
    "    for file in file_lst:\n",
    "        file_name = os.path.join(path, file)\n",
    "        df = pd.read_csv(file_name)\n",
    "        df = df[df.NUMOFBODIES != 0].reset_index(drop=True)\n",
    "###\n",
    "        if len(df) < 610:\n",
    "            pad_length = 610 - len(df)\n",
    "            pad_df = pd.DataFrame(0, index=range(len(df), 610), columns=df.columns)\n",
    "            df = pd.concat([df, pad_df])\n",
    "        df['index_num'] = df.index\n",
    "###\n",
    "        df_list.append(df)\n",
    "    #concat_df = pd.concat(df_list, ignore_index=True)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_mer = concat(folder_path_1)\n",
    "yugi_mer = concat(folder_path_2)\n",
    "jeon_mer = concat(folder_path_3)\n",
    "theft_mer = concat(folder_path_4)\n",
    "damage_mer = concat(folder_path_5)\n",
    "violence_mer = concat(folder_path_6)\n",
    "smoke_mer = concat(folder_path_7)\n",
    "buy_mer = concat(folder_path_8)\n",
    "refund_mer = concat(folder_path_9)\n",
    "compar_mer = concat(folder_path_10)\n",
    "select_mer = concat(folder_path_11)\n",
    "#test_mer = pd.concat(test_mer, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_mer = pd.concat(buy_mer, ignore_index=True)\n",
    "refund_mer = pd.concat(refund_mer, ignore_index=True)\n",
    "compar_mer = pd.concat(compar_mer, ignore_index=True)\n",
    "select_mer = pd.concat(select_mer, ignore_index=True)\n",
    "fire_mer = pd.concat(fire_mer, ignore_index=True)\n",
    "yugi_mer = pd.concat(yugi_mer, ignore_index=True)\n",
    "jeon_mer = pd.concat(jeon_mer, ignore_index=True)\n",
    "theft_mer = pd.concat(theft_mer, ignore_index=True)\n",
    "damage_mer = pd.concat(damage_mer, ignore_index=True)\n",
    "violence_mer = pd.concat(violence_mer, ignore_index=True)\n",
    "smoke_mer = pd.concat(smoke_mer, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buy_mer['LABEL'] = 0\n",
    "# refund_mer['LABEL'] = 1\n",
    "# compar_mer['LABEL'] = 2\n",
    "# select_mer['LABEL'] = 3\n",
    "fire_mer['LABEL'] = 0\n",
    "yugi_mer['LABEL'] = 1\n",
    "jeon_mer['LABEL'] = 2\n",
    "theft_mer['LABEL'] = 3\n",
    "damage_mer['LABEL'] = 4\n",
    "violence_mer['LABEL'] = 5\n",
    "smoke_mer['LABEL'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3121980, 57)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mer_lst = [fire_mer,\n",
    "            yugi_mer,\n",
    "            jeon_mer,\n",
    "            theft_mer,\n",
    "            damage_mer,\n",
    "            violence_mer,\n",
    "            smoke_mer]\n",
    "full_data = pd.concat(mer_lst, ignore_index=True)\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 레이블을 추출합니다\n",
    "label_data = full_data['LABEL']\n",
    "data_without_label = full_data.drop(columns=[col for col in full_data.columns if \"CONFIDENCE_LEVEL\" in col or \"spin\" in col.lower()])\n",
    "data_without_label = data_without_label.drop(['ID', 'TIMESTAMP', 'FRAME_NUM', 'LABEL', 'PELVIS_X', 'PELVIS_Y', 'NECK_X', 'NECK_Y'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMOFBODIES</th>\n",
       "      <th>SHOULDER_LEFT_X</th>\n",
       "      <th>SHOULDER_LEFT_Y</th>\n",
       "      <th>ELBOW_LEFT_X</th>\n",
       "      <th>ELBOW_LEFT_Y</th>\n",
       "      <th>WRIST_LEFT_X</th>\n",
       "      <th>WRIST_LEFT_Y</th>\n",
       "      <th>SHOULDER_RIGHT_X</th>\n",
       "      <th>SHOULDER_RIGHT_Y</th>\n",
       "      <th>ELBOW_RIGHT_X</th>\n",
       "      <th>...</th>\n",
       "      <th>ANKLE_LEFT_Y</th>\n",
       "      <th>HIP_RIGHT_X</th>\n",
       "      <th>HIP_RIGHT_Y</th>\n",
       "      <th>KNEE_RIGHT_X</th>\n",
       "      <th>KNEE_RIGHT_Y</th>\n",
       "      <th>ANKLE_RIGHT_X</th>\n",
       "      <th>ANKLE_RIGHT_Y</th>\n",
       "      <th>HEAD_X</th>\n",
       "      <th>HEAD_Y</th>\n",
       "      <th>index_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1278.1079</td>\n",
       "      <td>114.825320</td>\n",
       "      <td>1259.68320</td>\n",
       "      <td>171.31137</td>\n",
       "      <td>1241.9669</td>\n",
       "      <td>215.73785</td>\n",
       "      <td>1226.97250</td>\n",
       "      <td>114.992830</td>\n",
       "      <td>1220.18000</td>\n",
       "      <td>...</td>\n",
       "      <td>334.14374</td>\n",
       "      <td>1228.4524</td>\n",
       "      <td>203.73642</td>\n",
       "      <td>1207.98950</td>\n",
       "      <td>275.72427</td>\n",
       "      <td>1191.76420</td>\n",
       "      <td>341.46210</td>\n",
       "      <td>1257.8337</td>\n",
       "      <td>81.594730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1240.2539</td>\n",
       "      <td>110.277860</td>\n",
       "      <td>1237.18130</td>\n",
       "      <td>165.81174</td>\n",
       "      <td>1225.5015</td>\n",
       "      <td>210.13467</td>\n",
       "      <td>1183.58500</td>\n",
       "      <td>116.050810</td>\n",
       "      <td>1170.81820</td>\n",
       "      <td>...</td>\n",
       "      <td>334.11472</td>\n",
       "      <td>1193.4259</td>\n",
       "      <td>204.51294</td>\n",
       "      <td>1183.14620</td>\n",
       "      <td>274.82020</td>\n",
       "      <td>1178.65330</td>\n",
       "      <td>334.73154</td>\n",
       "      <td>1211.6045</td>\n",
       "      <td>82.707980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1212.6339</td>\n",
       "      <td>126.382416</td>\n",
       "      <td>1213.95890</td>\n",
       "      <td>184.40631</td>\n",
       "      <td>1210.9862</td>\n",
       "      <td>231.56741</td>\n",
       "      <td>1152.16580</td>\n",
       "      <td>122.803440</td>\n",
       "      <td>1141.23230</td>\n",
       "      <td>...</td>\n",
       "      <td>360.77667</td>\n",
       "      <td>1159.1150</td>\n",
       "      <td>219.64172</td>\n",
       "      <td>1150.11830</td>\n",
       "      <td>295.65607</td>\n",
       "      <td>1143.64160</td>\n",
       "      <td>366.48923</td>\n",
       "      <td>1186.4702</td>\n",
       "      <td>89.950500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1181.0144</td>\n",
       "      <td>127.760376</td>\n",
       "      <td>1186.65450</td>\n",
       "      <td>187.13950</td>\n",
       "      <td>1178.0974</td>\n",
       "      <td>236.86618</td>\n",
       "      <td>1122.35780</td>\n",
       "      <td>126.987976</td>\n",
       "      <td>1102.63810</td>\n",
       "      <td>...</td>\n",
       "      <td>371.67030</td>\n",
       "      <td>1125.3623</td>\n",
       "      <td>225.93182</td>\n",
       "      <td>1102.93850</td>\n",
       "      <td>302.86896</td>\n",
       "      <td>1106.12500</td>\n",
       "      <td>364.86044</td>\n",
       "      <td>1154.3636</td>\n",
       "      <td>92.412320</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1146.0264</td>\n",
       "      <td>132.623500</td>\n",
       "      <td>1154.95450</td>\n",
       "      <td>188.39767</td>\n",
       "      <td>1145.7614</td>\n",
       "      <td>237.44797</td>\n",
       "      <td>1081.51370</td>\n",
       "      <td>130.622990</td>\n",
       "      <td>1064.93000</td>\n",
       "      <td>...</td>\n",
       "      <td>363.16370</td>\n",
       "      <td>1087.5433</td>\n",
       "      <td>230.94366</td>\n",
       "      <td>1072.58940</td>\n",
       "      <td>311.27646</td>\n",
       "      <td>1060.65250</td>\n",
       "      <td>384.18704</td>\n",
       "      <td>1116.1233</td>\n",
       "      <td>94.339420</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1106.7562</td>\n",
       "      <td>133.512360</td>\n",
       "      <td>1114.76510</td>\n",
       "      <td>198.53070</td>\n",
       "      <td>1114.1066</td>\n",
       "      <td>251.99030</td>\n",
       "      <td>1037.67930</td>\n",
       "      <td>128.540800</td>\n",
       "      <td>1017.40216</td>\n",
       "      <td>...</td>\n",
       "      <td>383.37076</td>\n",
       "      <td>1052.1691</td>\n",
       "      <td>238.58942</td>\n",
       "      <td>1055.90560</td>\n",
       "      <td>320.79590</td>\n",
       "      <td>1061.89710</td>\n",
       "      <td>390.12524</td>\n",
       "      <td>1073.3724</td>\n",
       "      <td>91.784454</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1077.3759</td>\n",
       "      <td>144.557590</td>\n",
       "      <td>1086.47270</td>\n",
       "      <td>213.88540</td>\n",
       "      <td>1093.7473</td>\n",
       "      <td>267.94540</td>\n",
       "      <td>1005.54680</td>\n",
       "      <td>138.375610</td>\n",
       "      <td>995.79690</td>\n",
       "      <td>...</td>\n",
       "      <td>427.82190</td>\n",
       "      <td>1024.4401</td>\n",
       "      <td>256.36430</td>\n",
       "      <td>1034.81000</td>\n",
       "      <td>347.58856</td>\n",
       "      <td>1049.66110</td>\n",
       "      <td>380.17206</td>\n",
       "      <td>1042.2883</td>\n",
       "      <td>97.986510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1036.1980</td>\n",
       "      <td>160.768860</td>\n",
       "      <td>1039.04020</td>\n",
       "      <td>228.61484</td>\n",
       "      <td>1037.0474</td>\n",
       "      <td>282.61536</td>\n",
       "      <td>970.92426</td>\n",
       "      <td>148.121300</td>\n",
       "      <td>955.99194</td>\n",
       "      <td>...</td>\n",
       "      <td>430.36786</td>\n",
       "      <td>983.0804</td>\n",
       "      <td>263.34464</td>\n",
       "      <td>983.72736</td>\n",
       "      <td>350.56427</td>\n",
       "      <td>996.20490</td>\n",
       "      <td>422.37042</td>\n",
       "      <td>1005.3209</td>\n",
       "      <td>111.472900</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>978.0879</td>\n",
       "      <td>166.679530</td>\n",
       "      <td>986.88696</td>\n",
       "      <td>242.42532</td>\n",
       "      <td>975.7191</td>\n",
       "      <td>302.14178</td>\n",
       "      <td>929.82040</td>\n",
       "      <td>159.843110</td>\n",
       "      <td>936.25120</td>\n",
       "      <td>...</td>\n",
       "      <td>428.61435</td>\n",
       "      <td>933.3855</td>\n",
       "      <td>275.02808</td>\n",
       "      <td>917.14880</td>\n",
       "      <td>367.81520</td>\n",
       "      <td>904.82730</td>\n",
       "      <td>450.72455</td>\n",
       "      <td>954.7878</td>\n",
       "      <td>113.792020</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>926.4144</td>\n",
       "      <td>155.247070</td>\n",
       "      <td>943.20306</td>\n",
       "      <td>234.80420</td>\n",
       "      <td>940.6257</td>\n",
       "      <td>299.28412</td>\n",
       "      <td>851.75030</td>\n",
       "      <td>149.082920</td>\n",
       "      <td>834.78735</td>\n",
       "      <td>...</td>\n",
       "      <td>452.38995</td>\n",
       "      <td>879.2576</td>\n",
       "      <td>280.13672</td>\n",
       "      <td>881.57590</td>\n",
       "      <td>376.60764</td>\n",
       "      <td>891.61676</td>\n",
       "      <td>454.25742</td>\n",
       "      <td>885.6244</td>\n",
       "      <td>103.907166</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NUMOFBODIES  SHOULDER_LEFT_X  SHOULDER_LEFT_Y  ELBOW_LEFT_X  ELBOW_LEFT_Y  \\\n",
       "0            1        1278.1079       114.825320    1259.68320     171.31137   \n",
       "1            1        1240.2539       110.277860    1237.18130     165.81174   \n",
       "2            1        1212.6339       126.382416    1213.95890     184.40631   \n",
       "3            1        1181.0144       127.760376    1186.65450     187.13950   \n",
       "4            1        1146.0264       132.623500    1154.95450     188.39767   \n",
       "5            1        1106.7562       133.512360    1114.76510     198.53070   \n",
       "6            1        1077.3759       144.557590    1086.47270     213.88540   \n",
       "7            1        1036.1980       160.768860    1039.04020     228.61484   \n",
       "8            1         978.0879       166.679530     986.88696     242.42532   \n",
       "9            1         926.4144       155.247070     943.20306     234.80420   \n",
       "\n",
       "   WRIST_LEFT_X  WRIST_LEFT_Y  SHOULDER_RIGHT_X  SHOULDER_RIGHT_Y  \\\n",
       "0     1241.9669     215.73785        1226.97250        114.992830   \n",
       "1     1225.5015     210.13467        1183.58500        116.050810   \n",
       "2     1210.9862     231.56741        1152.16580        122.803440   \n",
       "3     1178.0974     236.86618        1122.35780        126.987976   \n",
       "4     1145.7614     237.44797        1081.51370        130.622990   \n",
       "5     1114.1066     251.99030        1037.67930        128.540800   \n",
       "6     1093.7473     267.94540        1005.54680        138.375610   \n",
       "7     1037.0474     282.61536         970.92426        148.121300   \n",
       "8      975.7191     302.14178         929.82040        159.843110   \n",
       "9      940.6257     299.28412         851.75030        149.082920   \n",
       "\n",
       "   ELBOW_RIGHT_X  ...  ANKLE_LEFT_Y  HIP_RIGHT_X  HIP_RIGHT_Y  KNEE_RIGHT_X  \\\n",
       "0     1220.18000  ...     334.14374    1228.4524    203.73642    1207.98950   \n",
       "1     1170.81820  ...     334.11472    1193.4259    204.51294    1183.14620   \n",
       "2     1141.23230  ...     360.77667    1159.1150    219.64172    1150.11830   \n",
       "3     1102.63810  ...     371.67030    1125.3623    225.93182    1102.93850   \n",
       "4     1064.93000  ...     363.16370    1087.5433    230.94366    1072.58940   \n",
       "5     1017.40216  ...     383.37076    1052.1691    238.58942    1055.90560   \n",
       "6      995.79690  ...     427.82190    1024.4401    256.36430    1034.81000   \n",
       "7      955.99194  ...     430.36786     983.0804    263.34464     983.72736   \n",
       "8      936.25120  ...     428.61435     933.3855    275.02808     917.14880   \n",
       "9      834.78735  ...     452.38995     879.2576    280.13672     881.57590   \n",
       "\n",
       "   KNEE_RIGHT_Y  ANKLE_RIGHT_X  ANKLE_RIGHT_Y     HEAD_X      HEAD_Y  \\\n",
       "0     275.72427     1191.76420      341.46210  1257.8337   81.594730   \n",
       "1     274.82020     1178.65330      334.73154  1211.6045   82.707980   \n",
       "2     295.65607     1143.64160      366.48923  1186.4702   89.950500   \n",
       "3     302.86896     1106.12500      364.86044  1154.3636   92.412320   \n",
       "4     311.27646     1060.65250      384.18704  1116.1233   94.339420   \n",
       "5     320.79590     1061.89710      390.12524  1073.3724   91.784454   \n",
       "6     347.58856     1049.66110      380.17206  1042.2883   97.986510   \n",
       "7     350.56427      996.20490      422.37042  1005.3209  111.472900   \n",
       "8     367.81520      904.82730      450.72455   954.7878  113.792020   \n",
       "9     376.60764      891.61676      454.25742   885.6244  103.907166   \n",
       "\n",
       "   index_num  \n",
       "0          0  \n",
       "1          1  \n",
       "2          2  \n",
       "3          3  \n",
       "4          4  \n",
       "5          5  \n",
       "6          6  \n",
       "7          7  \n",
       "8          8  \n",
       "9          9  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_label.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_start_indices = full_data.index[full_data['index_num'] == 0].tolist()\n",
    "sequence_lengths = [sequence_start_indices[i] - sequence_start_indices[i-1] for i in range(1, len(sequence_start_indices))]\n",
    "sequence_lengths.insert(0, sequence_start_indices[0])\n",
    "\n",
    "# Min sequence length\n",
    "min_sequence_length = min(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sequence_length = 610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5117, 610, 28), (5117,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "# Iterating over the start indices to create sequences\n",
    "for i in range(len(sequence_start_indices) - 1):\n",
    "    start_index = sequence_start_indices[i]\n",
    "    end_index = sequence_start_indices[i + 1]\n",
    "\n",
    "    # Ensure the sequence has the expected length before appending\n",
    "    if end_index - start_index == min_sequence_length:\n",
    "        X_sequence = data_without_label.iloc[start_index:end_index].values\n",
    "        y_sequence = label_data.iloc[start_index:end_index].values\n",
    "        X_sequences.append(X_sequence)\n",
    "        y_sequences.append(y_sequence[-1])  # Taking the label of the last frame for the sequence\n",
    "\n",
    "# Converting lists to numpy arrays\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_sequences = np.array(y_sequences)\n",
    "\n",
    "X_sequences.shape, y_sequences.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_sequences, y_sequences, test_size=0.3, random_state=48)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3581, 610, 28) (3581,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 610, 28) (1536,)\n"
     ]
    }
   ],
   "source": [
    "print(X_temp.shape, y_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.0000000e+00, 1.5867871e+03, 4.7891873e+02, ...,\n",
       "         1.5644379e+03, 3.8821814e+02, 0.0000000e+00],\n",
       "        [1.0000000e+00, 1.4441404e+03, 4.5919092e+02, ...,\n",
       "         1.4094054e+03, 3.7876883e+02, 1.0000000e+00],\n",
       "        [1.0000000e+00, 1.2822107e+03, 4.3106201e+02, ...,\n",
       "         1.2671614e+03, 3.5043677e+02, 2.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0700000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0800000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0900000e+02]],\n",
       "\n",
       "       [[1.0000000e+00, 1.4626862e+03, 5.2329285e+02, ...,\n",
       "         1.5254790e+03, 4.4302872e+02, 0.0000000e+00],\n",
       "        [1.0000000e+00, 1.3675514e+03, 4.8989725e+02, ...,\n",
       "         1.4176438e+03, 4.1209833e+02, 1.0000000e+00],\n",
       "        [1.0000000e+00, 1.2800908e+03, 4.4924902e+02, ...,\n",
       "         1.3294596e+03, 3.8021716e+02, 2.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0700000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0800000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0900000e+02]],\n",
       "\n",
       "       [[1.0000000e+00, 1.6073888e+03, 4.9847449e+02, ...,\n",
       "         1.5551763e+03, 4.1854407e+02, 0.0000000e+00],\n",
       "        [1.0000000e+00, 1.5142302e+03, 4.5537656e+02, ...,\n",
       "         1.5043918e+03, 3.6197696e+02, 1.0000000e+00],\n",
       "        [1.0000000e+00, 1.3900912e+03, 4.4088284e+02, ...,\n",
       "         1.3981306e+03, 3.5095157e+02, 2.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0700000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0800000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0900000e+02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.0000000e+00, 1.5138638e+03, 5.6661444e+02, ...,\n",
       "         1.5919351e+03, 4.7575378e+02, 0.0000000e+00],\n",
       "        [1.0000000e+00, 1.4287542e+03, 4.9467813e+02, ...,\n",
       "         1.4596371e+03, 3.9886786e+02, 1.0000000e+00],\n",
       "        [1.0000000e+00, 1.3321484e+03, 4.0631134e+02, ...,\n",
       "         1.3745532e+03, 3.6818695e+02, 2.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0700000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0800000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0900000e+02]],\n",
       "\n",
       "       [[1.0000000e+00, 1.2795582e+03, 3.3331036e+02, ...,\n",
       "         1.4023965e+03, 1.9909818e+02, 0.0000000e+00],\n",
       "        [1.0000000e+00, 1.1097373e+03, 3.4623230e+02, ...,\n",
       "         1.2249436e+03, 2.1005719e+02, 1.0000000e+00],\n",
       "        [1.0000000e+00, 1.0201665e+03, 3.3166882e+02, ...,\n",
       "         1.1281704e+03, 2.0876312e+02, 2.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0700000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0800000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0900000e+02]],\n",
       "\n",
       "       [[1.0000000e+00, 2.6196277e+02, 3.0890503e+02, ...,\n",
       "         3.5561853e+02, 2.3000140e+02, 0.0000000e+00],\n",
       "        [1.0000000e+00, 3.5397607e+02, 2.9093500e+02, ...,\n",
       "         4.2562207e+02, 2.1419434e+02, 1.0000000e+00],\n",
       "        [1.0000000e+00, 4.3273572e+02, 2.7705490e+02, ...,\n",
       "         4.8880750e+02, 1.8812943e+02, 2.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0700000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0800000e+02],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "         0.0000000e+00, 0.0000000e+00, 6.0900000e+02]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 모델 정의\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 훈련 데이터에 대한 샘플 가중치 마스크 생성\n",
    "# 패딩이 아닌 값은 1, 패딩된 값은 0\n",
    "sample_weight_train = np.where(X_train != 0, 1, 0)\n",
    "sample_weight_train = sample_weight_train.max(axis=-1)\n",
    "\n",
    "# 각 시퀀스에 대한 평균 샘플 가중치 계산\n",
    "sample_weight_train_avg = sample_weight_train.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "28/28 [==============================] - 133s 5s/step - loss: 1.7545 - accuracy: 0.2820 - val_loss: 1.6628 - val_accuracy: 0.3553\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 97s 3s/step - loss: 1.5596 - accuracy: 0.3734 - val_loss: 1.5836 - val_accuracy: 0.3553\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 111s 4s/step - loss: 1.4741 - accuracy: 0.3946 - val_loss: 1.5049 - val_accuracy: 0.4019\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 123s 4s/step - loss: 1.4510 - accuracy: 0.4228 - val_loss: 1.4951 - val_accuracy: 0.4037\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 108s 4s/step - loss: 1.4190 - accuracy: 0.4250 - val_loss: 1.4657 - val_accuracy: 0.4056\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 123s 4s/step - loss: 1.4680 - accuracy: 0.3974 - val_loss: 1.4856 - val_accuracy: 0.3888\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 142s 5s/step - loss: 1.4267 - accuracy: 0.4183 - val_loss: 1.4963 - val_accuracy: 0.4093\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 137s 5s/step - loss: 1.4078 - accuracy: 0.4281 - val_loss: 1.4681 - val_accuracy: 0.4270\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 130s 5s/step - loss: 1.4324 - accuracy: 0.4222 - val_loss: 1.5007 - val_accuracy: 0.4214\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 126s 4s/step - loss: 1.4326 - accuracy: 0.4164 - val_loss: 1.4534 - val_accuracy: 0.4158\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 125s 4s/step - loss: 1.4039 - accuracy: 0.4354 - val_loss: 1.4414 - val_accuracy: 0.4102\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 141s 5s/step - loss: 1.4105 - accuracy: 0.4236 - val_loss: 1.5082 - val_accuracy: 0.4037\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 114s 4s/step - loss: 1.4193 - accuracy: 0.4298 - val_loss: 1.4434 - val_accuracy: 0.4353\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 116s 4s/step - loss: 1.4017 - accuracy: 0.4415 - val_loss: 1.4671 - val_accuracy: 0.4112\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 119s 4s/step - loss: 1.4029 - accuracy: 0.4373 - val_loss: 1.4606 - val_accuracy: 0.4047\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 134s 5s/step - loss: 1.4028 - accuracy: 0.4415 - val_loss: 1.4437 - val_accuracy: 0.4307\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 123s 4s/step - loss: 1.3773 - accuracy: 0.4381 - val_loss: 1.4360 - val_accuracy: 0.4344\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 130s 5s/step - loss: 1.3710 - accuracy: 0.4379 - val_loss: 1.4094 - val_accuracy: 0.4307\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 117s 4s/step - loss: 1.3626 - accuracy: 0.4474 - val_loss: 1.4252 - val_accuracy: 0.4279\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 126s 5s/step - loss: 1.3764 - accuracy: 0.4423 - val_loss: 1.4317 - val_accuracy: 0.4130\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 126s 5s/step - loss: 1.3929 - accuracy: 0.4365 - val_loss: 1.4251 - val_accuracy: 0.4400\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 113s 4s/step - loss: 1.3653 - accuracy: 0.4521 - val_loss: 1.4098 - val_accuracy: 0.4381\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 136s 5s/step - loss: 1.3435 - accuracy: 0.4552 - val_loss: 1.3751 - val_accuracy: 0.4428\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 95s 3s/step - loss: 1.3496 - accuracy: 0.4529 - val_loss: 1.4178 - val_accuracy: 0.4270\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 95s 3s/step - loss: 1.3926 - accuracy: 0.4448 - val_loss: 1.4534 - val_accuracy: 0.4270\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 96s 3s/step - loss: 1.4006 - accuracy: 0.4300 - val_loss: 1.4362 - val_accuracy: 0.4074\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 96s 3s/step - loss: 1.3831 - accuracy: 0.4407 - val_loss: 1.3964 - val_accuracy: 0.4298\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 96s 3s/step - loss: 1.3694 - accuracy: 0.4460 - val_loss: 1.4747 - val_accuracy: 0.4167\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 96s 3s/step - loss: 1.3682 - accuracy: 0.4493 - val_loss: 1.3837 - val_accuracy: 0.4447\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 97s 3s/step - loss: 1.3524 - accuracy: 0.4451 - val_loss: 1.4490 - val_accuracy: 0.3944\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 97s 3s/step - loss: 1.3706 - accuracy: 0.4440 - val_loss: 1.3868 - val_accuracy: 0.4428\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 96s 3s/step - loss: 1.3215 - accuracy: 0.4638 - val_loss: 1.3924 - val_accuracy: 0.4167\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 97s 3s/step - loss: 1.3381 - accuracy: 0.4552 - val_loss: 1.4031 - val_accuracy: 0.4242\n",
      "15/15 [==============================] - 2s 163ms/step - loss: 1.2987 - accuracy: 0.4664\n",
      "Test Accuracy: 46.64%\n"
     ]
    }
   ],
   "source": [
    "model_file_path = \"./model/sum_all_32.h5\"\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_file_path)\n",
    "# - 자동 훈련 멈추기 함수 사용 : 추가 훈련 epoch 2회, 가중치 업데이트\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "\n",
    "# 4. Model Training\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1000,\n",
    "                    batch_size=128, sample_weight=sample_weight_train_avg,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "# 5. Model Evaluation\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model1 = load_model('./model/sum_all_32.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sequences, y_sequences\n",
    "X_val = X_sequences.astype(np.float32)\n",
    "y_val = y_sequences.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니크한 종속변수들을 얻습니다.\n",
    "unique_targets = np.unique(y_val)\n",
    "\n",
    "# 테스트 데이터에 대한 예측을 한 번만 수행\n",
    "test_preds = model1.predict(X_val)\n",
    "test_pred_idx = [np.argmax(pred) for pred in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "cate = ['구매(구매)', '구매(반품)', '구매(비교)', '구매(선택)',\n",
    "        '이상(방화)',\n",
    "        '이상(유기)',\n",
    "        '이상(전도)',\n",
    "        '이상(절도)',\n",
    "        '이상(파손)',\n",
    "        '이상(폭행)',\n",
    "        '이상(흡연)']\n",
    "\n",
    "def plot_confusion_matrix_with_labels(y_true, y_pred, labels):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix with custom labels.\n",
    "    \"\"\"\n",
    "    matrix = confusion_matrix(y_true, y_pred, labels=np.arange(len(labels)))\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    ax=sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# 실제 레이블과 예측 레이블 (y_val와 test_pred_idx)을 사용하여 Confusion Matrix를 시각화합니다.\n",
    "plot_confusion_matrix_with_labels(y_val, test_pred_idx, cate)\n",
    "\n",
    "# F1 Score를 계산합니다.\n",
    "f1 = f1_score(y_val, test_pred_idx, average='weighted')\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, test_pred_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
