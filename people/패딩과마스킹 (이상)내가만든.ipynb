{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import os\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"H:\\\\이상행동\"\n",
    "folders = os.listdir(base_path)\n",
    "file_name_lst = []\n",
    "folder_path_lst = []\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    folder_path_lst.append(folder_path)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.mp4'):\n",
    "            file_name_lst.append(os.path.join(folder_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1323"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_name_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_name_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_lst[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_1 = \"./data/이상(방화)\"\n",
    "folder_path_2 = \"./data/이상(유기)\"\n",
    "folder_path_3 = \"./data/이상(전도)\"\n",
    "folder_path_4 = \"./data/이상(절도)\"\n",
    "folder_path_5 = \"./data/이상(파손)\"\n",
    "folder_path_6 = \"./data/이상(폭행)\"\n",
    "folder_path_7 = \"./data/이상(흡연)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(path):\n",
    "    file_lst = os.listdir(path)\n",
    "    df_list = []\n",
    "    for file in file_lst:\n",
    "        file_name = os.path.join(path, file)\n",
    "        df = pd.read_csv(file_name)\n",
    "        df = df[df.NUMOFBODIES != 0].reset_index(drop=True)\n",
    "### 최대 인덱스 확인하고 싶으면 빼기\n",
    "        if len(df) < 484: # 최대 인덱스 설정하기\n",
    "            pad_length = 484 - len(df)\n",
    "            pad_df = pd.DataFrame(0, index=range(len(df), 484), columns=df.columns)\n",
    "            df = pd.concat([df, pad_df])\n",
    "        df['index_num'] = df.index\n",
    "        df_list.append(df)\n",
    "###\n",
    "    #concat_df = pd.concat(df_list, ignore_index=True)\n",
    "    #    df_list.append(df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_mer = concat(folder_path_1)\n",
    "yugi_mer = concat(folder_path_2)\n",
    "jeon_mer = concat(folder_path_3)\n",
    "theft_mer = concat(folder_path_4)\n",
    "damage_mer = concat(folder_path_5)\n",
    "violence_mer = concat(folder_path_6)\n",
    "smoke_mer = concat(folder_path_7)\n",
    "\n",
    "mer_lst = [fire_mer,\n",
    "            yugi_mer,\n",
    "            jeon_mer,\n",
    "            theft_mer,\n",
    "            damage_mer,\n",
    "            violence_mer,\n",
    "            smoke_mer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lengs(name):\n",
    "    lengths = []\n",
    "    for i in range(len(name)):\n",
    "        lengths.append(len(name[i]))\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengs(fire_mer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengsed = []\n",
    "for i in mer_lst:\n",
    "    lengsed.append(max(lengs(i)))\n",
    "lengsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_mer = pd.concat(fire_mer, ignore_index=True)\n",
    "yugi_mer = pd.concat(yugi_mer, ignore_index=True)\n",
    "jeon_mer = pd.concat(jeon_mer, ignore_index=True)\n",
    "theft_mer = pd.concat(theft_mer, ignore_index=True)\n",
    "damage_mer = pd.concat(damage_mer, ignore_index=True)\n",
    "violence_mer = pd.concat(violence_mer, ignore_index=True)\n",
    "smoke_mer = pd.concat(smoke_mer, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_mer['LABEL'] = 0  \n",
    "yugi_mer['LABEL'] = 1  \n",
    "jeon_mer['LABEL'] = 2\n",
    "theft_mer['LABEL'] = 3\n",
    "damage_mer['LABEL'] = 4\n",
    "violence_mer['LABEL'] = 5\n",
    "smoke_mer['LABEL'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer_lst = [fire_mer,\n",
    "            yugi_mer,\n",
    "            jeon_mer,\n",
    "            theft_mer,\n",
    "            damage_mer,\n",
    "            violence_mer,\n",
    "            smoke_mer]\n",
    "full_data = pd.concat(mer_lst, ignore_index=True)\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 레이블을 추출합니다.\n",
    "data_without_label = full_data.drop(['ID','LABEL', 'TIMESTAMP', 'FRAME_NUM','PELVIS_CONFIDENCE_LEVEL', 'SPINE_NAVA_CONFIDENCE_LEVEL', 'SPINE_CHEST_CONFIDENCE_LEVEL', 'NECK_CONFIDENCE_LEVEL', \n",
    "                                     'SHOULDER_LEFT_CONFIDENCE_LEVEL', 'ELBOW_LEFT_CONFIDENCE_LEVEL', 'WRIST_LEFT_CONFIDENCE_LEVEL', 'SHOULDER_RIGHT_CONFIDENCE_LEVEL', \n",
    "                                     'ELBOW_RIGHT_CONFIDENCE_LEVEL', 'WRIST_RIGHT_CONFIDENCE_LEVEL', 'HIP_LEFT_CONFIDENCE_LEVEL', 'KNEE_LEFT_CONFIDENCE_LEVEL', 'ANKLE_LEFT_CONFIDENCE_LEVEL',\n",
    "                                     'HIP_RIGHT_CONFIDENCE_LEVEL', 'KNEE_RIGHT_CONFIDENCE_LEVEL', 'ANKLE_RIGHT_CONFIDENCE_LEVEL', 'HEAD_CONFIDENCE_LEVEL'], axis=1)\n",
    "label_data = full_data['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_start_indices = full_data.index[full_data['index_num'] == 0].tolist()\n",
    "sequence_lengths = [sequence_start_indices[i] - sequence_start_indices[i-1] for i in range(1, len(sequence_start_indices))]\n",
    "sequence_lengths.insert(0, sequence_start_indices[0])\n",
    "\n",
    "# Min sequence length\n",
    "min_sequence_length = min(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sequence_length = 484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "# Iterating over the start indices to create sequences\n",
    "for i in range(len(sequence_start_indices) - 1):\n",
    "    start_index = sequence_start_indices[i]\n",
    "    end_index = sequence_start_indices[i + 1]\n",
    "    \n",
    "    # Ensure the sequence has the expected length before appending\n",
    "    if end_index - start_index == min_sequence_length:\n",
    "        X_sequence = data_without_label.iloc[start_index:end_index].values\n",
    "        y_sequence = label_data.iloc[start_index:end_index].values\n",
    "        X_sequences.append(X_sequence)\n",
    "        y_sequences.append(y_sequence[-1])  # Taking the label of the last frame for the sequence\n",
    "\n",
    "# Converting lists to numpy arrays\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_sequences = np.array(y_sequences)\n",
    "\n",
    "X_sequences.shape, y_sequences.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_sequences, y_sequences, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 모델 정의\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 훈련 데이터에 대한 샘플 가중치 마스크 생성\n",
    "# 패딩이 아닌 값은 1, 패딩된 값은 0\n",
    "sample_weight_train = np.where(X_train != 0, 1, 0)\n",
    "sample_weight_train = sample_weight_train.max(axis=-1)\n",
    "\n",
    "# 각 시퀀스에 대한 평균 샘플 가중치 계산\n",
    "sample_weight_train_avg = sample_weight_train.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = \"./model/notnormal_lstm_model1.h5\"\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_file_path)\n",
    "# - 자동 훈련 멈추기 함수 사용 : 추가 훈련 epoch 2회, 가중치 업데이트\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "\n",
    "# 4. Model Training\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1000,\n",
    "                    batch_size=128, sample_weight=sample_weight_train_avg,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "# 5. Model Evaluation\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model1 = load_model('./model/best_lstm_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 불러온 모델로 데이터 정확도 확인하기\n",
    "# - 예측\n",
    "test_preds = model1.predict(X_val)\n",
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - 정답갯수 / 오답 갯수 (100개 데이터에 대해서만)\n",
    "# - 정답률 / 오답률 (100개 데이터에 대해서만)\n",
    "test_pred_idx = [np.argmax(pred) for pred in test_preds]\n",
    "test_pred_idx\n",
    "\n",
    "all_cnt = len(test_pred_idx)\n",
    "o_cnt = len(y_val[(test_pred_idx == y_val)])\n",
    "x_cnt = len(y_val[(test_pred_idx != y_val)])\n",
    "\n",
    "print(\"정답갯수 : {}개, 오답갯수 : {}개\".format(o_cnt, x_cnt))\n",
    "print(\"정답률 : {}%, 오답률 : {}%\".format(o_cnt/all_cnt*100,\n",
    "                                        x_cnt/all_cnt*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = ['이상(방화)',\n",
    "'이상(유기)',\n",
    "'이상(전도)',\n",
    "'이상(절도)',\n",
    "'이상(파손)',\n",
    "'이상(폭행)',\n",
    "'이상(흡연)',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니크한 종속변수들을 얻습니다.\n",
    "unique_targets = np.unique(y_val)\n",
    "\n",
    "# 테스트 데이터에 대한 예측을 한 번만 수행\n",
    "test_preds = model1.predict(X_val)\n",
    "test_pred_idx = [np.argmax(pred) for pred in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_idx = np.array(test_pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 종속변수별 정확도를 저장할 데이터프레임\n",
    "accuracy_per_target = pd.DataFrame(index=unique_targets, columns=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스별 정확도 계산\n",
    "class_accuracies = {}\n",
    "for i in np.unique(y_val):\n",
    "    idx = np.where(y_val == i)\n",
    "    correct = np.sum(test_pred_idx[idx] == y_val[idx])\n",
    "    total = len(idx[0])\n",
    "    class_accuracies[i] = correct / total\n",
    "    accuracy_per_target.loc[i, 'accuracy'] = class_accuracies[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_target[\"Target\"] = cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df_sorted = accuracy_per_target.sort_values(by='accuracy', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
