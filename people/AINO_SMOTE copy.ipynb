{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "\n",
    "# pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실행결과 동일하게(완전 일치하지는 않음)\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "### 텐서 연산 고정(완전 일치하지는 않음)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = 원본데이터 | data2 = 원본데이터 복붙 | data3 = 우리가 측정한 데이터\n",
    "folder_path_1 = \"./data/이상(방화)\"\n",
    "folder_path_2 = \"./data/이상(유기)\"\n",
    "folder_path_3 = \"./data/이상(전도)\"\n",
    "folder_path_5 = \"./data/가방\"\n",
    "folder_path_6 = \"./data/주머니\"\n",
    "folder_path_7 = \"./data/이상(파손)\"\n",
    "folder_path_8 = \"./data/이상(폭행)\"\n",
    "folder_path_9 = \"./data/이상(흡연)\"\n",
    "folder_path_10 = \"./data/구매(구매)\"\n",
    "folder_path_11 = \"./data/구매(반품)\"\n",
    "folder_path_12 = \"./data/구매(비교)\"\n",
    "folder_path_13 = \"./data/구매(선택)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def concat(path):\n",
    "    file_lst = os.listdir(path)\n",
    "    df_list = []\n",
    "\n",
    "    for file in file_lst:\n",
    "        file_name = os.path.join(path, file)\n",
    "        df = pd.read_csv(file_name)\n",
    "        df = df[df.NUMOFBODIES != 0].reset_index(drop=True)\n",
    "\n",
    "        # 각 열을 순차적으로 뺍니다.\n",
    "        for i in range(1, df.shape[1]-1):  # 첫 번째 열을 제외하고 시작\n",
    "            # 변환: 문자열이 포함된 열을 숫자로 변환\n",
    "            df[df.columns[i]] = pd.to_numeric(df[df.columns[i]], errors='coerce')\n",
    "            df[df.columns[i+1]] = pd.to_numeric(df[df.columns[i+1]], errors='coerce')\n",
    "\n",
    "            # 원래의 열에 연산 결과 할당\n",
    "            df.loc[df.index[:-1], df.columns[i]] = df[df.columns[i]].iloc[1:].values - df[df.columns[i]].iloc[:-1].values\n",
    "\n",
    "        # 길이가 610보다 짧은 경우 패딩 추가\n",
    "        if len(df) < 610:\n",
    "            pad_length = 610 - len(df)\n",
    "            pad_df = pd.DataFrame(0, index=range(len(df), 610), columns=df.columns)\n",
    "            df = pd.concat([df, pad_df])\n",
    "        df['index_num'] = df.index\n",
    "\n",
    "        df_list.append(df)\n",
    "\n",
    "    return df_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lst = os.listdir(folder_path_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.drop(full_data.columns[1:14], axis=1)\n",
    "full_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_label = full_data.drop(['LABEL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_start_indices = full_data.index[full_data['index_num'] == 0].tolist()\n",
    "sequence_lengths = [sequence_start_indices[i] - sequence_start_indices[i-1] for i in range(1, len(sequence_start_indices))]\n",
    "sequence_lengths.insert(0, sequence_start_indices[0])\n",
    "\n",
    "# Min sequence length\n",
    "min_sequence_length = min(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sequence_length = 610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sequences = []\n",
    "\n",
    "# Iterating over the start indices to create sequences\n",
    "for i in range(len(sequence_start_indices) - 1):\n",
    "    start_index = sequence_start_indices[i]\n",
    "    end_index = sequence_start_indices[i + 1]\n",
    "\n",
    "    # Ensure the sequence has the expected length before appending\n",
    "    if end_index - start_index == min_sequence_length:\n",
    "        X_sequence = data_without_label.iloc[start_index:end_index].values\n",
    "        X_sequences.append(X_sequence)\n",
    "\n",
    "# Converting lists to numpy arrays\n",
    "X_sequences = np.array(X_sequences)\n",
    "\n",
    "X_sequences.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_sequences, y_sequences, test_size=0.3, random_state=48)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 오버샘플링 (SMOTE)\n",
    "#  - 2차원 이하 차원만 가능\n",
    "\n",
    "# 학습데이터 차원 낮추기 (3차원 -> 2차원)\n",
    "# X_train.shape -> (4303, 610, 32)\n",
    "X_train = X_train.reshape(4303, 610 * 28)\n",
    "\n",
    "# SMOTE를 적용할 때는 반드시 !!학습 데이터!!만 오버샘플링해야 함\n",
    "smote = SMOTE(random_state=48)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "X_smote.shape, y_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래대로 차원 늘리기 (2차원 -> 3차원)\n",
    "# X_smote의 변경된 데이터 개수로 바꿔주기\n",
    "# - 행위마다 오버샘플링 시 데이터 개수가 다름\n",
    "X_smote = X_smote.reshape(7606, 610, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_temp.shape, y_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "X_smote = X_smote.astype(np.float32)\n",
    "y_smote = y_smote.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 모델 정의\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(X_smote.shape[1], X_smote.shape[2])),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 훈련 데이터에 대한 샘플 가중치 마스크 생성\n",
    "# 패딩이 아닌 값은 1, 패딩된 값은 0\n",
    "sample_weight_train = np.where(X_smote != 0, 1, 0)\n",
    "sample_weight_train = sample_weight_train.max(axis=-1)\n",
    "\n",
    "# 각 시퀀스에 대한 평균 샘플 가중치 계산\n",
    "sample_weight_train_avg = sample_weight_train.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!행위마다 모델 이름 변경하기!!!!!\n",
    "model_file_path = \"./model/yugi.h5\"\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_file_path)\n",
    "# - 자동 훈련 멈추기 함수 사용 : 추가 훈련 epoch 3회, 가중치 업데이트\n",
    "# - patience : 검증 손실의 최소값에 도달한 후 중단하기 전에 기다려야 하는 epoch 수\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 5,\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_smote, y_smote, validation_data=(X_val, y_val), epochs=20,\n",
    "                    batch_size=128, sample_weight=sample_weight_train_avg,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "from keras.models import load_model\n",
    "model1 = load_model('./model/jeon.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sequences\n",
    "X_val = X_sequences.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 예측을 한 번만 수행\n",
    "test_preds = model1.predict(X_val)\n",
    "test_pred_idx = [np.argmax(pred) for pred in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 실제 레이블과 예측 레이블을 사용하여 Confusion Matrix를 계산합니다.\n",
    "conf_matrix = confusion_matrix(y_val, test_pred_idx)\n",
    "\n",
    "# F1 Score를 계산합니다.\n",
    "f1 = f1_score(y_val, test_pred_idx, average='weighted')\n",
    "\n",
    "# Confusion Matrix를 시각화합니다.\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "# 모델에 맞게 타이틀 변경하기\n",
    "plt.title('smoke smote')\n",
    "plt.show()\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, test_pred_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
