{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import os\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow import keras\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = 원본데이터 | data2 = 우리가 측정한 데이터\n",
    "folder_path_1 = \"./data/이상(방화)\"\n",
    "folder_path_2 = \"./data/이상(유기)\"\n",
    "folder_path_3 = \"./data/이상(전도)\"\n",
    "folder_path_4 = \"./data/가방\"\n",
    "folder_path_5 = \"./data/이상(파손)\"\n",
    "folder_path_6 = \"./data/이상(폭행)\"\n",
    "folder_path_7 = \"./data/이상(흡연)\"\n",
    "#folder_path_7 = \"./data/이상(교통약자)\"\n",
    "folder_path_8 = \"./data/구매(구매)\"\n",
    "folder_path_9 = \"./data/구매(반품)\"\n",
    "folder_path_10 = \"./data/구매(비교)\"\n",
    "folder_path_11 = \"./data/구매(선택)\"\n",
    "folder_path_12 = \"./data/주머니\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(path):\n",
    "    file_lst = os.listdir(path)\n",
    "    df_list = []\n",
    "    for file in file_lst:\n",
    "        file_name = os.path.join(path, file)\n",
    "        df = pd.read_csv(file_name)\n",
    "        df = df[df.NUMOFBODIES != 0].reset_index(drop=True)\n",
    "# ### 인덱스 크기 확인하려면 주석\n",
    "#         if len(df) < 610:\n",
    "#             pad_length = 610 - len(df)\n",
    "#             pad_df = pd.DataFrame(0, index=range(len(df), 610), columns=df.columns)\n",
    "#             df = pd.concat([df, pad_df])\n",
    "#         df['index_num'] = df.index\n",
    "# ###\n",
    "        df_list.append(df)\n",
    "    #concat_df = pd.concat(df_list, ignore_index=True)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_mer = concat(folder_path_1)\n",
    "yugi_mer = concat(folder_path_2)\n",
    "jeon_mer = concat(folder_path_3)\n",
    "gabang_mer = concat(folder_path_4)\n",
    "damage_mer = concat(folder_path_5)\n",
    "violence_mer = concat(folder_path_6)\n",
    "smoke_mer = concat(folder_path_7)\n",
    "buy_mer = concat(folder_path_8)\n",
    "refund_mer = concat(folder_path_9)\n",
    "compar_mer = concat(folder_path_10)\n",
    "select_mer = concat(folder_path_11)\n",
    "jumoney_mer = concat(folder_path_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer_lst = [fire_mer,\n",
    "            yugi_mer,\n",
    "            jeon_mer,\n",
    "            jumoney_mer,\n",
    "            gabang_mer,\n",
    "            damage_mer,\n",
    "            violence_mer,\n",
    "            smoke_mer,\n",
    "            buy_mer,\n",
    "            refund_mer,\n",
    "            compar_mer,\n",
    "            select_mer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lengs(name):\n",
    "    lengths = []\n",
    "    for i in range(len(name)):\n",
    "        lengths.append(len(name[i]))\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[733, 722, 726, 191, 437, 722, 722, 772, 244, 253, 247, 287]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengs(mer_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[165,\n",
       " 161,\n",
       " 158,\n",
       " 158,\n",
       " 131,\n",
       " 138,\n",
       " 135,\n",
       " 140,\n",
       " 150,\n",
       " 154,\n",
       " 151,\n",
       " 154,\n",
       " 316,\n",
       " 144,\n",
       " 141,\n",
       " 146,\n",
       " 134,\n",
       " 135,\n",
       " 140,\n",
       " 163,\n",
       " 160,\n",
       " 157,\n",
       " 132,\n",
       " 146,\n",
       " 150,\n",
       " 149,\n",
       " 152,\n",
       " 152,\n",
       " 157,\n",
       " 152,\n",
       " 158,\n",
       " 318,\n",
       " 163,\n",
       " 159,\n",
       " 164,\n",
       " 138,\n",
       " 146,\n",
       " 154,\n",
       " 154,\n",
       " 151,\n",
       " 139,\n",
       " 142,\n",
       " 147,\n",
       " 150,\n",
       " 139,\n",
       " 145,\n",
       " 141,\n",
       " 147,\n",
       " 148,\n",
       " 152,\n",
       " 148,\n",
       " 154,\n",
       " 293,\n",
       " 129,\n",
       " 125,\n",
       " 89,\n",
       " 165,\n",
       " 161,\n",
       " 159,\n",
       " 113,\n",
       " 115,\n",
       " 114,\n",
       " 118,\n",
       " 117,\n",
       " 147,\n",
       " 152,\n",
       " 151,\n",
       " 156,\n",
       " 152,\n",
       " 155,\n",
       " 157,\n",
       " 322,\n",
       " 157,\n",
       " 154,\n",
       " 157,\n",
       " 155,\n",
       " 153,\n",
       " 155,\n",
       " 139,\n",
       " 138,\n",
       " 138,\n",
       " 144,\n",
       " 141,\n",
       " 147,\n",
       " 145,\n",
       " 150,\n",
       " 137,\n",
       " 142,\n",
       " 138,\n",
       " 143,\n",
       " 332,\n",
       " 157,\n",
       " 154,\n",
       " 157,\n",
       " 137,\n",
       " 142,\n",
       " 162,\n",
       " 156,\n",
       " 159,\n",
       " 109,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 143,\n",
       " 149,\n",
       " 147,\n",
       " 152,\n",
       " 150,\n",
       " 153,\n",
       " 150,\n",
       " 155,\n",
       " 287,\n",
       " 126,\n",
       " 125,\n",
       " 140,\n",
       " 139,\n",
       " 145,\n",
       " 162,\n",
       " 155,\n",
       " 159,\n",
       " 139,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 142,\n",
       " 133,\n",
       " 141,\n",
       " 138,\n",
       " 143,\n",
       " 140,\n",
       " 144,\n",
       " 140,\n",
       " 146,\n",
       " 302,\n",
       " 129,\n",
       " 126,\n",
       " 129,\n",
       " 122,\n",
       " 123,\n",
       " 126,\n",
       " 166,\n",
       " 164,\n",
       " 162,\n",
       " 144,\n",
       " 142,\n",
       " 144,\n",
       " 151,\n",
       " 150,\n",
       " 121,\n",
       " 127,\n",
       " 123,\n",
       " 129,\n",
       " 147,\n",
       " 151,\n",
       " 149,\n",
       " 151,\n",
       " 294,\n",
       " 118,\n",
       " 114,\n",
       " 118,\n",
       " 115,\n",
       " 119,\n",
       " 162,\n",
       " 153,\n",
       " 159,\n",
       " 120,\n",
       " 121,\n",
       " 120,\n",
       " 119,\n",
       " 122,\n",
       " 150,\n",
       " 155,\n",
       " 153,\n",
       " 158,\n",
       " 147,\n",
       " 152,\n",
       " 149,\n",
       " 153,\n",
       " 315,\n",
       " 153,\n",
       " 149,\n",
       " 154,\n",
       " 148,\n",
       " 142,\n",
       " 146,\n",
       " 150,\n",
       " 155,\n",
       " 149,\n",
       " 151,\n",
       " 123,\n",
       " 123,\n",
       " 124,\n",
       " 124,\n",
       " 138,\n",
       " 144,\n",
       " 142,\n",
       " 147,\n",
       " 138,\n",
       " 145,\n",
       " 143,\n",
       " 147,\n",
       " 136,\n",
       " 133,\n",
       " 136,\n",
       " 138,\n",
       " 131,\n",
       " 132,\n",
       " 135,\n",
       " 160,\n",
       " 153,\n",
       " 157,\n",
       " 120,\n",
       " 122,\n",
       " 116,\n",
       " 129,\n",
       " 125,\n",
       " 134,\n",
       " 141,\n",
       " 138,\n",
       " 144,\n",
       " 152,\n",
       " 156,\n",
       " 153,\n",
       " 157,\n",
       " 324,\n",
       " 164,\n",
       " 160,\n",
       " 164,\n",
       " 164,\n",
       " 155,\n",
       " 159,\n",
       " 129,\n",
       " 134,\n",
       " 131,\n",
       " 141,\n",
       " 137,\n",
       " 144,\n",
       " 148,\n",
       " 147,\n",
       " 152,\n",
       " 150,\n",
       " 152,\n",
       " 150,\n",
       " 154,\n",
       " 319,\n",
       " 143,\n",
       " 140,\n",
       " 144,\n",
       " 162,\n",
       " 159,\n",
       " 155,\n",
       " 135,\n",
       " 143,\n",
       " 139,\n",
       " 147,\n",
       " 145,\n",
       " 139,\n",
       " 146,\n",
       " 144,\n",
       " 150,\n",
       " 144,\n",
       " 149,\n",
       " 148,\n",
       " 153,\n",
       " 252,\n",
       " 143,\n",
       " 140,\n",
       " 143,\n",
       " 155,\n",
       " 150,\n",
       " 150,\n",
       " 120,\n",
       " 122,\n",
       " 122,\n",
       " 124,\n",
       " 126,\n",
       " 125,\n",
       " 129,\n",
       " 130,\n",
       " 134,\n",
       " 140,\n",
       " 136,\n",
       " 140,\n",
       " 129,\n",
       " 130,\n",
       " 132,\n",
       " 130,\n",
       " 127,\n",
       " 127,\n",
       " 128,\n",
       " 130,\n",
       " 164,\n",
       " 162,\n",
       " 165,\n",
       " 150,\n",
       " 152,\n",
       " 153,\n",
       " 158,\n",
       " 142,\n",
       " 143,\n",
       " 147,\n",
       " 147,\n",
       " 150,\n",
       " 154,\n",
       " 152,\n",
       " 155,\n",
       " 146,\n",
       " 146,\n",
       " 148,\n",
       " 146,\n",
       " 148,\n",
       " 149,\n",
       " 151,\n",
       " 155,\n",
       " 152,\n",
       " 148,\n",
       " 148,\n",
       " 159,\n",
       " 157,\n",
       " 158,\n",
       " 161,\n",
       " 136,\n",
       " 137,\n",
       " 139,\n",
       " 140,\n",
       " 155,\n",
       " 160,\n",
       " 158,\n",
       " 161,\n",
       " 141,\n",
       " 142,\n",
       " 145,\n",
       " 144,\n",
       " 143,\n",
       " 145,\n",
       " 146,\n",
       " 148,\n",
       " 163,\n",
       " 156,\n",
       " 160,\n",
       " 128,\n",
       " 131,\n",
       " 130,\n",
       " 136,\n",
       " 135,\n",
       " 135,\n",
       " 137,\n",
       " 137,\n",
       " 146,\n",
       " 151,\n",
       " 148,\n",
       " 152,\n",
       " 140,\n",
       " 141,\n",
       " 144,\n",
       " 142,\n",
       " 131,\n",
       " 133,\n",
       " 165,\n",
       " 162,\n",
       " 158,\n",
       " 135,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 142,\n",
       " 152,\n",
       " 153,\n",
       " 155,\n",
       " 155,\n",
       " 137,\n",
       " 141,\n",
       " 136,\n",
       " 136,\n",
       " 141,\n",
       " 140,\n",
       " 191,\n",
       " 139,\n",
       " 140,\n",
       " 142,\n",
       " 146,\n",
       " 155,\n",
       " 162,\n",
       " 134,\n",
       " 137,\n",
       " 133,\n",
       " 145,\n",
       " 140,\n",
       " 153,\n",
       " 154,\n",
       " 157,\n",
       " 158,\n",
       " 150,\n",
       " 154,\n",
       " 153,\n",
       " 155,\n",
       " 146,\n",
       " 146,\n",
       " 149,\n",
       " 148,\n",
       " 191,\n",
       " 139,\n",
       " 140,\n",
       " 142,\n",
       " 146,\n",
       " 151,\n",
       " 164,\n",
       " 142,\n",
       " 151,\n",
       " 146,\n",
       " 157,\n",
       " 152,\n",
       " 125,\n",
       " 125,\n",
       " 129,\n",
       " 129,\n",
       " 139,\n",
       " 131,\n",
       " 130,\n",
       " 126,\n",
       " 130,\n",
       " 131,\n",
       " 133,\n",
       " 138,\n",
       " 151,\n",
       " 159,\n",
       " 136,\n",
       " 136,\n",
       " 139,\n",
       " 139,\n",
       " 152,\n",
       " 157,\n",
       " 155,\n",
       " 157,\n",
       " 146,\n",
       " 146,\n",
       " 148,\n",
       " 147,\n",
       " 198,\n",
       " 199,\n",
       " 146,\n",
       " 149,\n",
       " 159,\n",
       " 154,\n",
       " 152,\n",
       " 156,\n",
       " 157,\n",
       " 153,\n",
       " 163,\n",
       " 160,\n",
       " 156,\n",
       " 161,\n",
       " 159,\n",
       " 163,\n",
       " 155,\n",
       " 157,\n",
       " 156,\n",
       " 159,\n",
       " 333,\n",
       " 160,\n",
       " 157,\n",
       " 161,\n",
       " 146,\n",
       " 146,\n",
       " 151,\n",
       " 150,\n",
       " 162,\n",
       " 156,\n",
       " 123,\n",
       " 123,\n",
       " 126,\n",
       " 126,\n",
       " 152,\n",
       " 156,\n",
       " 154,\n",
       " 156,\n",
       " 144,\n",
       " 144,\n",
       " 145,\n",
       " 206,\n",
       " 147,\n",
       " 149,\n",
       " 151,\n",
       " 143,\n",
       " 148,\n",
       " 164,\n",
       " 124,\n",
       " 124,\n",
       " 127,\n",
       " 128,\n",
       " 143,\n",
       " 150,\n",
       " 147,\n",
       " 151,\n",
       " 129,\n",
       " 130,\n",
       " 134,\n",
       " 132,\n",
       " 164,\n",
       " 157,\n",
       " 140,\n",
       " 143,\n",
       " 146,\n",
       " 163,\n",
       " 160,\n",
       " 136,\n",
       " 136,\n",
       " 140,\n",
       " 139,\n",
       " 154,\n",
       " 159,\n",
       " 156,\n",
       " 159,\n",
       " 139,\n",
       " 140,\n",
       " 143,\n",
       " 149,\n",
       " 163,\n",
       " 157,\n",
       " 110,\n",
       " 111,\n",
       " 114,\n",
       " 113,\n",
       " 149,\n",
       " 154,\n",
       " 152,\n",
       " 154,\n",
       " 296,\n",
       " 118,\n",
       " 119,\n",
       " 122,\n",
       " 148,\n",
       " 163,\n",
       " 160,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 170,\n",
       " 169,\n",
       " 173,\n",
       " 171,\n",
       " 173,\n",
       " 172,\n",
       " 172,\n",
       " 341,\n",
       " 169,\n",
       " 166,\n",
       " 167,\n",
       " 156,\n",
       " 166,\n",
       " 215,\n",
       " 174,\n",
       " 174,\n",
       " 176,\n",
       " 176,\n",
       " 157,\n",
       " 161,\n",
       " 159,\n",
       " 162,\n",
       " 169,\n",
       " 169,\n",
       " 171,\n",
       " 336,\n",
       " 166,\n",
       " 166,\n",
       " 168,\n",
       " 150,\n",
       " 161,\n",
       " 198,\n",
       " 148,\n",
       " 148,\n",
       " 150,\n",
       " 151,\n",
       " 156,\n",
       " 161,\n",
       " 158,\n",
       " 161,\n",
       " 153,\n",
       " 154,\n",
       " 153,\n",
       " 155,\n",
       " 157,\n",
       " 159,\n",
       " 150,\n",
       " 161,\n",
       " 172,\n",
       " 128,\n",
       " 132,\n",
       " 149,\n",
       " 154,\n",
       " 151,\n",
       " 154,\n",
       " 123,\n",
       " 126,\n",
       " 125,\n",
       " 127,\n",
       " 128,\n",
       " 130,\n",
       " 132,\n",
       " 154,\n",
       " 162,\n",
       " 234,\n",
       " 125,\n",
       " 126,\n",
       " 129,\n",
       " 128,\n",
       " 149,\n",
       " 153,\n",
       " 102,\n",
       " 103,\n",
       " 291,\n",
       " 212,\n",
       " 116,\n",
       " 119,\n",
       " 153,\n",
       " 165,\n",
       " 165,\n",
       " 162,\n",
       " 158,\n",
       " 152,\n",
       " 155,\n",
       " 154,\n",
       " 159,\n",
       " 162,\n",
       " 152,\n",
       " 156,\n",
       " 155,\n",
       " 158,\n",
       " 160,\n",
       " 164,\n",
       " 161,\n",
       " 165,\n",
       " 341,\n",
       " 163,\n",
       " 161,\n",
       " 165,\n",
       " 154,\n",
       " 152,\n",
       " 160,\n",
       " 163,\n",
       " 160,\n",
       " 163,\n",
       " 126,\n",
       " 128,\n",
       " 127,\n",
       " 131,\n",
       " 131,\n",
       " 128,\n",
       " 135,\n",
       " 132,\n",
       " 138,\n",
       " 161,\n",
       " 158,\n",
       " 161,\n",
       " 331,\n",
       " 156,\n",
       " 154,\n",
       " 158,\n",
       " 125,\n",
       " 125,\n",
       " 130,\n",
       " 159,\n",
       " 157,\n",
       " 155,\n",
       " 154,\n",
       " 153,\n",
       " 153,\n",
       " 157,\n",
       " 160,\n",
       " 166,\n",
       " 164,\n",
       " 169,\n",
       " 158,\n",
       " 160,\n",
       " 158,\n",
       " 162,\n",
       " 303,\n",
       " 126,\n",
       " 123,\n",
       " 127,\n",
       " 138,\n",
       " 163,\n",
       " 162,\n",
       " 160,\n",
       " 130,\n",
       " 129,\n",
       " 125,\n",
       " 136,\n",
       " 132,\n",
       " 133,\n",
       " 141,\n",
       " 138,\n",
       " 142,\n",
       " 160,\n",
       " 161,\n",
       " 160,\n",
       " 164,\n",
       " 328,\n",
       " 155,\n",
       " 151,\n",
       " 157,\n",
       " 147,\n",
       " 163,\n",
       " 161,\n",
       " 157,\n",
       " 144,\n",
       " 144,\n",
       " 139,\n",
       " 152,\n",
       " 147,\n",
       " 129,\n",
       " 136,\n",
       " 134,\n",
       " 140,\n",
       " 150,\n",
       " 154,\n",
       " 151,\n",
       " 156,\n",
       " 307,\n",
       " 132,\n",
       " 128,\n",
       " 133,\n",
       " 113,\n",
       " 115,\n",
       " 118,\n",
       " 154,\n",
       " 151,\n",
       " 149,\n",
       " 117,\n",
       " 113,\n",
       " 112,\n",
       " 124,\n",
       " 121,\n",
       " 161,\n",
       " 168,\n",
       " 165,\n",
       " 170,\n",
       " 158,\n",
       " 163,\n",
       " 159,\n",
       " 164,\n",
       " 352,\n",
       " 174,\n",
       " 170,\n",
       " 174,\n",
       " 157,\n",
       " 160,\n",
       " 164,\n",
       " 161,\n",
       " 154,\n",
       " 156,\n",
       " 141,\n",
       " 143,\n",
       " 141,\n",
       " 148,\n",
       " 146,\n",
       " 156,\n",
       " 163,\n",
       " 160,\n",
       " 166,\n",
       " 157,\n",
       " 160,\n",
       " 159,\n",
       " 162,\n",
       " 284,\n",
       " 158,\n",
       " 155,\n",
       " 159,\n",
       " 161,\n",
       " 160,\n",
       " 168]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengs(smoke_mer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140.38199181446112,\n",
       " 130.27285318559558,\n",
       " 160.0082644628099,\n",
       " 155.55497382198953,\n",
       " 150.49199084668192,\n",
       " 139.39612188365652,\n",
       " 268.33795013850414,\n",
       " 152.05310880829015,\n",
       " 416.41803278688525,\n",
       " 408.02766798418975,\n",
       " 443.9068825910931,\n",
       " 329.94425087108016]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengsed = []\n",
    "for i in mer_lst:\n",
    "    lengsed.append(statistics.mean(lengs(i)))\n",
    "lengsedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[313, 310, 308, 326, 309, 315, 484, 352, 540, 556, 550, 502]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengsed = []\n",
    "for i in mer_lst:\n",
    "    lengsed.append(max(lengs(i)))\n",
    "lengsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_mer = pd.concat(buy_mer, ignore_index=True)\n",
    "refund_mer = pd.concat(refund_mer, ignore_index=True)\n",
    "compar_mer = pd.concat(compar_mer, ignore_index=True)\n",
    "select_mer = pd.concat(select_mer, ignore_index=True)\n",
    "#test_mer = pd.concat(test_mer, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_mer['LABEL'] = 0  \n",
    "refund_mer['LABEL'] = 1  \n",
    "compar_mer['LABEL'] = 2\n",
    "select_mer['LABEL'] = 3\n",
    "#test_mer['LABEL'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_lst = [buy_mer, refund_mer, compar_mer, select_mer] # test_mer\n",
    "full_data = pd.concat(category_lst, ignore_index=True)\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 레이블을 추출합니다\n",
    "label_data = full_data['LABEL']\n",
    "data_without_label = full_data.drop(['ID', 'TIMESTAMP', 'FRAME_NUM', 'LABEL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_start_indices = full_data.index[full_data['index_num'] == 0].tolist()\n",
    "sequence_lengths = [sequence_start_indices[i] - sequence_start_indices[i-1] for i in range(1, len(sequence_start_indices))]\n",
    "sequence_lengths.insert(0, sequence_start_indices[0])\n",
    "\n",
    "# Min sequence length\n",
    "min_sequence_length = min(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sequence_length = 610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "# Iterating over the start indices to create sequences\n",
    "for i in range(len(sequence_start_indices) - 1):\n",
    "    start_index = sequence_start_indices[i]\n",
    "    end_index = sequence_start_indices[i + 1]\n",
    "    \n",
    "    # Ensure the sequence has the expected length before appending\n",
    "    if end_index - start_index == min_sequence_length:\n",
    "        X_sequence = data_without_label.iloc[start_index:end_index].values\n",
    "        y_sequence = label_data.iloc[start_index:end_index].values\n",
    "        X_sequences.append(X_sequence)\n",
    "        y_sequences.append(y_sequence[-1])  # Taking the label of the last frame for the sequence\n",
    "\n",
    "# Converting lists to numpy arrays\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_sequences = np.array(y_sequences)\n",
    "\n",
    "X_sequences.shape, y_sequences.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_sequences, y_sequences, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 모델 정의\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 훈련 데이터에 대한 샘플 가중치 마스크 생성\n",
    "# 패딩이 아닌 값은 1, 패딩된 값은 0\n",
    "sample_weight_train = np.where(X_train != 0, 1, 0)\n",
    "sample_weight_train = sample_weight_train.max(axis=-1)\n",
    "\n",
    "# 각 시퀀스에 대한 평균 샘플 가중치 계산\n",
    "sample_weight_train_avg = sample_weight_train.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = \"./model/best_lstm_model_tttt.h5\"\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_file_path)\n",
    "# - 자동 훈련 멈추기 함수 사용 : 추가 훈련 epoch 2회, 가중치 업데이트\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "\n",
    "# 4. Model Training\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1000,\n",
    "                    batch_size=128, sample_weight=sample_weight_train_avg,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "# 5. Model Evaluation\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model1 = load_model('./model/best_lstm_model_tttt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 불러온 모델로 데이터 정확도 확인하기\n",
    "# - 예측\n",
    "test_preds = model1.predict(X_val)\n",
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - 정답갯수 / 오답 갯수 (100개 데이터에 대해서만)\n",
    "# - 정답률 / 오답률 (100개 데이터에 대해서만)\n",
    "test_pred_idx = [np.argmax(pred) for pred in test_preds]\n",
    "test_pred_idx\n",
    "\n",
    "all_cnt = len(test_pred_idx)\n",
    "o_cnt = len(y_val[(test_pred_idx == y_val)])\n",
    "x_cnt = len(y_val[(test_pred_idx != y_val)])\n",
    "\n",
    "print(\"정답갯수 : {}개, 오답갯수 : {}개\".format(o_cnt, x_cnt))\n",
    "print(\"정답률 : {}%, 오답률 : {}%\".format(o_cnt/all_cnt*100,\n",
    "                                        x_cnt/all_cnt*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = ['구매(구매)', '구매(반품)', '구매(비교)', '구매(선택)']#'구매(시험)',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니크한 종속변수들을 얻습니다.\n",
    "unique_targets = np.unique(y_val)\n",
    "\n",
    "# 테스트 데이터에 대한 예측을 한 번만 수행\n",
    "test_preds = model1.predict(X_val)\n",
    "test_pred_idx = [np.argmax(pred) for pred in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_idx = np.array(test_pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 종속변수별 정확도를 저장할 데이터프레임\n",
    "accuracy_per_target = pd.DataFrame(index=unique_targets, columns=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스별 정확도 계산\n",
    "class_accuracies = {}\n",
    "for i in np.unique(y_val):\n",
    "    idx = np.where(y_val == i)\n",
    "    correct = np.sum(test_pred_idx[idx] == y_val[idx])\n",
    "    total = len(idx[0])\n",
    "    class_accuracies[i] = correct / total\n",
    "    accuracy_per_target.loc[i, 'accuracy'] = class_accuracies[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_target[\"Target\"] = cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df_sorted = accuracy_per_target.sort_values(by='accuracy', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
